{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91644eb5-2aa4-47a1-943b-3cbeaf219a40",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d79ed21-4b8b-4e25-8952-1323447d85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802dc138-2f34-409d-a717-aea65390a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afde3529-7581-4193-89da-f84b10ed4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from llama_index.core.response.notebook_utils import display_source_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e11b61-80e4-4890-a885-847e61aef4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio \n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aaa1227-b601-43de-a4fe-57011cedc56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa2dcc-221d-4d32-8898-0b2c0d1d9612",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8432698b-17b9-437a-b95e-1901589ad009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"EXPERIMENT_NAME\": \"Healthcare bot\",\n",
       "  \"RUN_NAME\": \"03_chatbot_ui\",\n",
       "  \"RUN_DESCRIPTION\": \"\\n# Objective\\nCreate ui chatbot\\n    \",\n",
       "  \"TESTING\": false,\n",
       "  \"DEBUG\": false,\n",
       "  \"OBSERVABILITY\": true,\n",
       "  \"LOG_TO_MLFLOW\": true,\n",
       "  \"CREATE_RETRIEVAL_EVAL_DATASET\": false,\n",
       "  \"RECREATE_RESPONSE_EVAL_DATASET\": false,\n",
       "  \"RECREATE_INDEX\": false\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.run.args import RunInputArgs\n",
    "\n",
    "ARGS = RunInputArgs(\n",
    "    EXPERIMENT_NAME=\"Healthcare bot\",\n",
    "    RUN_NAME=\"03_chatbot_ui\",\n",
    "    RUN_DESCRIPTION=\"\"\"\n",
    "# Objective\n",
    "Create ui chatbot\n",
    "    \"\"\",\n",
    "    TESTING=False,\n",
    "    DEBUG=False,\n",
    "    OBSERVABILITY=True,\n",
    "    LOG_TO_MLFLOW=True,\n",
    "    CREATE_RETRIEVAL_EVAL_DATASET=False,\n",
    "    RECREATE_RESPONSE_EVAL_DATASET=False,\n",
    "    RECREATE_INDEX=False,\n",
    ")\n",
    "ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a82d62-eaf7-404a-bdd1-64e4cc92cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-24 22:54:56.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.run.cfg\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1mStarting Observability server with Phoenix...\u001b[0m\n",
      "INFO:phoenix.config:ðŸ“‹ Ensuring phoenix working directory: /home/nampq/.phoenix\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1727193302.086376   20399 chttp2_server.cc:1118] UNKNOWN:No address added out of total 1 resolved for '[::]:4317' {created_time:\"2024-09-24T22:55:02.086360521+07:00\", children:[UNKNOWN:Failed to add any wildcard listeners {created_time:\"2024-09-24T22:55:02.086350318+07:00\", children:[UNKNOWN:Unable to configure socket {fd:65, created_time:\"2024-09-24T22:55:02.086323254+07:00\", children:[UNKNOWN:bind: Address already in use (98) {created_time:\"2024-09-24T22:55:02.08630348+07:00\"}]}, UNKNOWN:Unable to configure socket {fd:65, created_time:\"2024-09-24T22:55:02.086347781+07:00\", children:[UNKNOWN:bind: Address already in use (98) {created_time:\"2024-09-24T22:55:02.086344578+07:00\"}]}]}]}\n",
      "ERROR:    Traceback (most recent call last):\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/starlette/routing.py\", line 732, in lifespan\n",
      "    async with self.lifespan_context(app) as maybe_state:\n",
      "  File \"/home/nampq/miniconda3/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/fastapi/routing.py\", line 131, in merged_lifespan\n",
      "    async with original_context(app) as maybe_original_state:\n",
      "  File \"/home/nampq/miniconda3/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/fastapi/routing.py\", line 131, in merged_lifespan\n",
      "    async with original_context(app) as maybe_original_state:\n",
      "  File \"/home/nampq/miniconda3/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/fastapi/routing.py\", line 131, in merged_lifespan\n",
      "    async with original_context(app) as maybe_original_state:\n",
      "  File \"/home/nampq/miniconda3/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/phoenix/server/app.py\", line 406, in lifespan\n",
      "    await stack.enter_async_context(grpc_server)\n",
      "  File \"/home/nampq/miniconda3/lib/python3.12/contextlib.py\", line 659, in enter_async_context\n",
      "    result = await _enter(cm)\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/phoenix/server/grpc_server.py\", line 80, in __aenter__\n",
      "    server.add_insecure_port(f\"[::]:{get_env_grpc_port()}\")\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/grpc/aio/_server.py\", line 102, in add_insecure_port\n",
      "    return _common.validate_port_binding_result(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/nampq/.cache/pypoetry/virtualenvs/personal-bot-bBSbD0Py-py3.12/lib/python3.12/site-packages/grpc/_common.py\", line 181, in validate_port_binding_result\n",
      "    raise RuntimeError(_ERROR_MESSAGE_PORT_BINDING_FAILED % address)\n",
      "RuntimeError: Failed to bind to address [::]:4317; set GRPC_VERBOSITY=debug environment variable to see detailed error message.\n",
      "\n",
      "ERROR:    Application startup failed. Exiting.\n",
      "ERROR [phoenix.session.session] ðŸ’¥ Phoenix failed to start. Please try again (making sure that port 6006 is not occupied by another process) or file an issue with us at https://github.com/Arize-ai/phoenix\n",
      "\u001b[32m2024-09-24 22:55:02.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.run.cfg\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mSetting up MLflow experiment Healthcare bot - run 03_chatbot_ui...\u001b[0m\n",
      "\u001b[32m2024-09-24 22:55:03.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.run.cfg\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mNotebook-generated artifacts are persisted at data/03_chatbot_ui\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.run.cfg import RunConfig\n",
    "\n",
    "cfg = RunConfig()\n",
    "cfg.init(ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72af5ecb-6827-4456-99c2-74c1c3fe7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf31aedb-5675-4e46-bae7-60aecfb9240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Gemini(\n",
    "    model_name=\"models/gemini-1.5-flash\",\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f330639b-82e9-4d85-91b2-47e4334c0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac40f7eb-e043-4d68-b7ca-efa8b319eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample Tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad2d27c6-293b-4b01-8fc8-ca9b61985e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(tools=[multiply_tool], llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afafbba2-875b-41c6-b652-cdab77abd17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 7b2392d0-dd9f-4ecc-ae81-1818fe5f91be. Step input: 2023 * 2025 báº±ng máº¥y?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Vietnamese. I need to use a tool to help me answer the question.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2023, 'b': 2025}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 4096575\n",
      "\u001b[0m> Running step 9a29b971-98d1-464e-be51-fe379916fd0d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 2023 * 2025 báº±ng 4096575.\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='2023 * 2025 báº±ng 4096575.', sources=[ToolOutput(content='4096575', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 2023, 'b': 2025}}, raw_output=4096575, is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat(\"2023 * 2025 báº±ng máº¥y?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c919dbd7-4a1d-410d-a747-31060c37841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 781c2f86-b212-4bef-a8cb-00ef41d51304. Step input: 2023 * 2025 báº±ng máº¥y?\n",
      "\u001b[1;3;38;5;200mThought: I need to use a tool to calculate the product.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2023, 'b': 2025}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 4096575\n",
      "\u001b[0m> Running step 96aa1e56-2c22-4a57-b098-31409208fd84. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 2023 * 2025 báº±ng 4096575.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "res = agent.chat(\"2023 * 2025 báº±ng máº¥y?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9b1528d-ec6e-4af1-9f37-ddaea5b557fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023 * 2025 báº±ng 4096575.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d49703-c2e3-401d-b38a-1316654bb6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
